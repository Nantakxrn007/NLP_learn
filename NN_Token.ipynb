{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b434cd96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\mini\\envs\\pine\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Run setup code\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "from huggingface_hub import hf_hub_download\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# To guarantee reproducible results\n",
    "torch.manual_seed(5420)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(5420)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50d3bb4",
   "metadata": {},
   "source": [
    "Download datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27a00ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8bba226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85f733ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'corpora.tar.gz'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_hub_download(repo_id=\"iristun/corpora\", filename=\"corpora.tar.gz\", repo_type=\"dataset\", local_dir=\".\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a180c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x corpora/\n",
      "x corpora/mnist_data/\n",
      "x corpora/mnist_data/t10k-images-idx3-ubyte.gz\n",
      "x corpora/mnist_data/train-images-idx3-ubyte.gz\n",
      "x corpora/mnist_data/.ipynb_checkpoints/\n",
      "x corpora/mnist_data/vis_utils.py\n",
      "x corpora/mnist_data/__init__.py\n",
      "x corpora/mnist_data/load_mnist.py\n",
      "x corpora/mnist_data/train-labels-idx1-ubyte.gz\n",
      "x corpora/mnist_data/t10k-labels-idx1-ubyte.gz\n",
      "x corpora/BEST/\n",
      "x corpora/BEST/test/\n",
      "x corpora/BEST/test/df_best_article_test.csv\n",
      "x corpora/BEST/test/df_best_encyclopedia_test.csv\n",
      "x corpora/BEST/test/df_best_novel_test.csv\n",
      "x corpora/BEST/test/df_best_news_test.csv\n",
      "x corpora/BEST/train/\n",
      "x corpora/BEST/train/df_best_encyclopedia_train.csv\n",
      "x corpora/BEST/train/df_best_article_train.csv\n",
      "x corpora/BEST/train/df_best_news_train.csv\n",
      "x corpora/BEST/train/df_best_novel_train.csv\n",
      "x corpora/BEST/val/\n",
      "x corpora/BEST/val/df_best_encyclopedia_val.csv\n",
      "x corpora/BEST/val/df_best_news_val.csv\n",
      "x corpora/BEST/val/df_best_article_val.csv\n",
      "x corpora/BEST/val/df_best_novel_val.csv\n",
      "x corpora/.ipynb_checkpoints/\n",
      "x corpora/.ipynb_checkpoints/Word_Tokenizer.new-checkpoint.ipynb\n",
      "x corpora/.ipynb_checkpoints/BackProp-checkpoint.ipynb\n",
      "x corpora/.ipynb_checkpoints/Word_Tokenizer_backup-checkpoint.ipynb\n",
      "x corpora/.ipynb_checkpoints/char2vec-checkpoint.ipynb\n",
      "x corpora/.ipynb_checkpoints/Word_Tokenizer-checkpoint.ipynb\n",
      "x corpora/cattern/\n",
      "x corpora/cattern/gradient_check.py\n",
      "x corpora/cattern/.ipynb_checkpoints/\n",
      "x corpora/cattern/__init__.py\n",
      "x corpora/cattern/data_utils.py\n",
      "x corpora/wiki/\n",
      "x corpora/wiki/thwiki_chk.txt\n"
     ]
    }
   ],
   "source": [
    "!tar xvf corpora.tar.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " ' ': 1,\n",
       " '!': 2,\n",
       " '\"': 3,\n",
       " '#': 4,\n",
       " '$': 5,\n",
       " '%': 6,\n",
       " '&': 7,\n",
       " \"'\": 8,\n",
       " '(': 9,\n",
       " ')': 10,\n",
       " '*': 11,\n",
       " '+': 12,\n",
       " ',': 13,\n",
       " '-': 14,\n",
       " '.': 15,\n",
       " '/': 16,\n",
       " '0': 17,\n",
       " '1': 18,\n",
       " '2': 19,\n",
       " '3': 20,\n",
       " '4': 21,\n",
       " '5': 22,\n",
       " '6': 23,\n",
       " '7': 24,\n",
       " '8': 25,\n",
       " '9': 26,\n",
       " ':': 27,\n",
       " ';': 28,\n",
       " '<': 29,\n",
       " '=': 30,\n",
       " '>': 31,\n",
       " '?': 32,\n",
       " '@': 33,\n",
       " 'A': 34,\n",
       " 'B': 35,\n",
       " 'C': 36,\n",
       " 'D': 37,\n",
       " 'E': 38,\n",
       " 'F': 39,\n",
       " 'G': 40,\n",
       " 'H': 41,\n",
       " 'I': 42,\n",
       " 'J': 43,\n",
       " 'K': 44,\n",
       " 'L': 45,\n",
       " 'M': 46,\n",
       " 'N': 47,\n",
       " 'O': 48,\n",
       " 'P': 49,\n",
       " 'Q': 50,\n",
       " 'R': 51,\n",
       " 'S': 52,\n",
       " 'T': 53,\n",
       " 'U': 54,\n",
       " 'V': 55,\n",
       " 'W': 56,\n",
       " 'X': 57,\n",
       " 'Y': 58,\n",
       " 'Z': 59,\n",
       " '[': 60,\n",
       " '\\\\': 61,\n",
       " ']': 62,\n",
       " '^': 63,\n",
       " '_': 64,\n",
       " 'a': 65,\n",
       " 'b': 66,\n",
       " 'c': 67,\n",
       " 'd': 68,\n",
       " 'e': 69,\n",
       " 'f': 70,\n",
       " 'g': 71,\n",
       " 'h': 72,\n",
       " 'i': 73,\n",
       " 'j': 74,\n",
       " 'k': 75,\n",
       " 'l': 76,\n",
       " 'm': 77,\n",
       " 'n': 78,\n",
       " 'o': 79,\n",
       " 'other': 80,\n",
       " 'p': 81,\n",
       " 'q': 82,\n",
       " 'r': 83,\n",
       " 's': 84,\n",
       " 't': 85,\n",
       " 'u': 86,\n",
       " 'v': 87,\n",
       " 'w': 88,\n",
       " 'x': 89,\n",
       " 'y': 90,\n",
       " 'z': 91,\n",
       " '}': 92,\n",
       " '~': 93,\n",
       " 'ก': 94,\n",
       " 'ข': 95,\n",
       " 'ฃ': 96,\n",
       " 'ค': 97,\n",
       " 'ฅ': 98,\n",
       " 'ฆ': 99,\n",
       " 'ง': 100,\n",
       " 'จ': 101,\n",
       " 'ฉ': 102,\n",
       " 'ช': 103,\n",
       " 'ซ': 104,\n",
       " 'ฌ': 105,\n",
       " 'ญ': 106,\n",
       " 'ฎ': 107,\n",
       " 'ฏ': 108,\n",
       " 'ฐ': 109,\n",
       " 'ฑ': 110,\n",
       " 'ฒ': 111,\n",
       " 'ณ': 112,\n",
       " 'ด': 113,\n",
       " 'ต': 114,\n",
       " 'ถ': 115,\n",
       " 'ท': 116,\n",
       " 'ธ': 117,\n",
       " 'น': 118,\n",
       " 'บ': 119,\n",
       " 'ป': 120,\n",
       " 'ผ': 121,\n",
       " 'ฝ': 122,\n",
       " 'พ': 123,\n",
       " 'ฟ': 124,\n",
       " 'ภ': 125,\n",
       " 'ม': 126,\n",
       " 'ย': 127,\n",
       " 'ร': 128,\n",
       " 'ฤ': 129,\n",
       " 'ล': 130,\n",
       " 'ว': 131,\n",
       " 'ศ': 132,\n",
       " 'ษ': 133,\n",
       " 'ส': 134,\n",
       " 'ห': 135,\n",
       " 'ฬ': 136,\n",
       " 'อ': 137,\n",
       " 'ฮ': 138,\n",
       " 'ฯ': 139,\n",
       " 'ะ': 140,\n",
       " 'ั': 141,\n",
       " 'า': 142,\n",
       " 'ำ': 143,\n",
       " 'ิ': 144,\n",
       " 'ี': 145,\n",
       " 'ึ': 146,\n",
       " 'ื': 147,\n",
       " 'ุ': 148,\n",
       " 'ู': 149,\n",
       " 'ฺ': 150,\n",
       " 'เ': 151,\n",
       " 'แ': 152,\n",
       " 'โ': 153,\n",
       " 'ใ': 154,\n",
       " 'ไ': 155,\n",
       " 'ๅ': 156,\n",
       " 'ๆ': 157,\n",
       " '็': 158,\n",
       " '่': 159,\n",
       " '้': 160,\n",
       " '๊': 161,\n",
       " '๋': 162,\n",
       " '์': 163,\n",
       " 'ํ': 164,\n",
       " '๐': 165,\n",
       " '๑': 166,\n",
       " '๒': 167,\n",
       " '๓': 168,\n",
       " '๔': 169,\n",
       " '๕': 170,\n",
       " '๖': 171,\n",
       " '๗': 172,\n",
       " '๘': 173,\n",
       " '๙': 174,\n",
       " '‘': 175,\n",
       " '’': 176,\n",
       " '\\ufeff': 177}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a character map\n",
    "CHARS = [\n",
    "  '\\n', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+',\n",
    "  ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8',\n",
    "  '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B', 'C', 'D', 'E',\n",
    "  'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R',\n",
    "  'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\\\', ']', '^', '_',\n",
    "  'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm',\n",
    "  'n', 'o', 'other', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y',\n",
    "  'z', '}', '~', 'ก', 'ข', 'ฃ', 'ค', 'ฅ', 'ฆ', 'ง', 'จ', 'ฉ', 'ช',\n",
    "  'ซ', 'ฌ', 'ญ', 'ฎ', 'ฏ', 'ฐ', 'ฑ', 'ฒ', 'ณ', 'ด', 'ต', 'ถ', 'ท',\n",
    "  'ธ', 'น', 'บ', 'ป', 'ผ', 'ฝ', 'พ', 'ฟ', 'ภ', 'ม', 'ย', 'ร', 'ฤ',\n",
    "  'ล', 'ว', 'ศ', 'ษ', 'ส', 'ห', 'ฬ', 'อ', 'ฮ', 'ฯ', 'ะ', 'ั', 'า',\n",
    "  'ำ', 'ิ', 'ี', 'ึ', 'ื', 'ุ', 'ู', 'ฺ', 'เ', 'แ', 'โ', 'ใ', 'ไ',\n",
    "  'ๅ', 'ๆ', '็', '่', '้', '๊', '๋', '์', 'ํ', '๐', '๑', '๒', '๓',\n",
    "  '๔', '๕', '๖', '๗', '๘', '๙', '‘', '’', '\\ufeff'\n",
    "]\n",
    "CHARS_MAP = {v: k for k, v in enumerate(CHARS)}\n",
    "print(type(CHARS_MAP))\n",
    "CHARS_MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5af4e43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_n_gram_df(df, n_pad):\n",
    "  \"\"\"\n",
    "  Given an input dataframe, create a feature dataframe of shifted characters\n",
    "  Input:\n",
    "  df: timeseries of size (N)\n",
    "  n_pad: the number of context. For a given character at position [idx],\n",
    "    character at position [idx-n_pad/2 : idx+n_pad/2] will be used\n",
    "    as features for that character.\n",
    "\n",
    "  Output:\n",
    "  dataframe of size (N * n_pad) which each row contains the character,\n",
    "    n_pad_2 characters to the left, and n_pad_2 characters to the right\n",
    "    of that character.\n",
    "  \"\"\"\n",
    "  n_pad_2 = int((n_pad - 1)/2)\n",
    "  for i in range(n_pad_2):\n",
    "      df['char-{}'.format(i+1)] = df['char'].shift(i + 1)\n",
    "      df['char{}'.format(i+1)] = df['char'].shift(-i - 1)\n",
    "  return df[n_pad_2: -n_pad_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7f20949",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_feature(best_processed_path, option='train'):\n",
    "  \"\"\"\n",
    "  Transform the path to a directory containing processed files\n",
    "  into a feature matrix and output array\n",
    "  Input:\n",
    "  best_processed_path: str, path to a processed version of the BEST dataset\n",
    "  option: str, 'train' or 'test'\n",
    "  \"\"\"\n",
    "  # we use padding equals 21 here to consider 10 characters to the left\n",
    "  # and 10 characters to the right as features for the character in the middle\n",
    "  n_pad = 21\n",
    "  n_pad_2 = int((n_pad - 1)/2)\n",
    "  pad = [{'char': ' ', 'target': True}]\n",
    "  df_pad = pd.DataFrame(pad * n_pad_2)\n",
    "\n",
    "  df = []\n",
    "  # article types in BEST corpus\n",
    "  article_types = ['article', 'encyclopedia', 'news', 'novel']\n",
    "  for article_type in article_types:\n",
    "      df.append(pd.read_csv(os.path.join(best_processed_path, option, 'df_best_{}_{}.csv'.format(article_type, option))))\n",
    "\n",
    "  df = pd.concat(df)\n",
    "  # pad with empty string feature\n",
    "  df = pd.concat((df_pad, df, df_pad))\n",
    "\n",
    "  # map characters to numbers, use 'other' if not in the predefined character set.\n",
    "  df['char'] = df['char'].map(lambda x: CHARS_MAP.get(x, 80))\n",
    "\n",
    "  # Use nearby characters as features\n",
    "  df_with_context = create_n_gram_df(df, n_pad=n_pad)\n",
    "\n",
    "  char_row = ['char' + str(i + 1) for i in range(n_pad_2)] + \\\n",
    "             ['char-' + str(i + 1) for i in range(n_pad_2)] + ['char']\n",
    "\n",
    "  # convert pandas dataframe to numpy array to feed to the model\n",
    "  x_char = df_with_context[char_row].to_numpy()\n",
    "  y = df_with_context['target'].astype(int).to_numpy()\n",
    "\n",
    "  return x_char, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a55fe98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the preprocessed data\n",
    "best_processed_path = 'corpora/BEST'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "157b4958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape:  (16461637, 21)\n",
      "Training data labels shape:  (16461637,)\n",
      "Validation data shape:  (2035694, 21)\n",
      "Validation data labels shape:  (2035694,)\n",
      "Test data shape:  (2271932, 21)\n",
      "Test data labels shape:  (2271932,)\n"
     ]
    }
   ],
   "source": [
    "# Load preprocessed BEST corpus\n",
    "x_train_char, y_train = prepare_feature(best_processed_path, option='train')\n",
    "x_val_char, y_val = prepare_feature(best_processed_path, option='val')\n",
    "x_test_char, y_test = prepare_feature(best_processed_path, option='test')\n",
    "\n",
    "# As a sanity check, we print out the size of the training, val, and test data.\n",
    "print('Training data shape: ', x_train_char.shape)\n",
    "print('Training data labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', x_val_char.shape)\n",
    "print('Validation data labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', x_test_char.shape)\n",
    "print('Test data labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2fb353d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 21 features:  [[112. 140. 114. 148. 130. 142.  94. 142. 128. 128.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.  97.]\n",
      " [140. 114. 148. 130. 142.  94. 142. 128. 128. 141.  97.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1. 112.]]\n",
      "First 2 class labels [1 0]\n"
     ]
    }
   ],
   "source": [
    "# Print some entry from the data to make sure it is the same as what you think.\n",
    "print('First 21 features: ', x_train_char[:2,:21])\n",
    "print('First 2 class labels', y_train[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b6611e",
   "metadata": {},
   "source": [
    "| char10 | ... | char2 | char1 | **char** | char-1 | char-2 | ... | char-10 |\n",
    "| ------ | --- | ----- | ----- | -------- | ------ | ------ | --- | ------- |\n",
    "| 0      | ... | 0     | 0     | **1**    | 2      | 3      | ... | 0       |\n",
    "| ...    |     |       |       | **2**    | 3      | 4      | ... | 0       |\n",
    "| ...    |     |       |       | **3**    | 4      | 5      | ... | 0       |\n",
    "| ...    |     |       |       | **6**    | 7      | 0      | ... | 0       |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fb97b02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ค:  ค ณะตุลาการร\tpred = 1\n",
      "ณ: ค ณ ะตุลาการรั\tpred = 0\n",
      "ะ: คณ ะ ตุลาการรัฐ\tpred = 0\n",
      "ต: คณะ ต ุลาการรัฐธ\tpred = 0\n",
      "ุ: คณะต ุ ลาการรัฐธร\tpred = 0\n",
      "ล: คณะตุ ล าการรัฐธรร\tpred = 0\n",
      "า: คณะตุล า การรัฐธรรม\tpred = 0\n",
      "ก: คณะตุลา ก ารรัฐธรรมน\tpred = 0\n",
      "า: คณะตุลาก า รรัฐธรรมนู\tpred = 0\n",
      "ร: คณะตุลากา ร รัฐธรรมนูญ\tpred = 0\n",
      "ร: คณะตุลาการ ร ัฐธรรมนูญก\tpred = 0\n",
      "ั: ณะตุลาการร ั ฐธรรมนูญกั\tpred = 0\n",
      "ฐ: ะตุลาการรั ฐ ธรรมนูญกับ\tpred = 0\n",
      "ธ: ตุลาการรัฐ ธ รรมนูญกับค\tpred = 0\n",
      "ร: ุลาการรัฐธ ร รมนูญกับคว\tpred = 0\n",
      "ร: ลาการรัฐธร ร มนูญกับควา\tpred = 0\n",
      "ม: าการรัฐธรร ม นูญกับความ\tpred = 0\n",
      "น: การรัฐธรรม น ูญกับความเ\tpred = 0\n",
      "ู: ารรัฐธรรมน ู ญกับความเป\tpred = 0\n",
      "ญ: รรัฐธรรมนู ญ กับความเป็\tpred = 0\n",
      "ก: รัฐธรรมนูญ ก ับความเป็น\tpred = 1\n",
      "ั: ัฐธรรมนูญก ั บความเป็นอ\tpred = 0\n",
      "บ: ฐธรรมนูญกั บ ความเป็นอง\tpred = 0\n",
      "ค: ธรรมนูญกับ ค วามเป็นองค\tpred = 1\n",
      "ว: รรมนูญกับค ว ามเป็นองค์\tpred = 0\n",
      "า: รมนูญกับคว า มเป็นองค์ก\tpred = 0\n",
      "ม: มนูญกับควา ม เป็นองค์กร\tpred = 0\n",
      "เ: นูญกับความ เ ป็นองค์กรต\tpred = 1\n",
      "ป: ูญกับความเ ป ็นองค์กรตุ\tpred = 0\n",
      "็: ญกับความเป ็ นองค์กรตุล\tpred = 0\n"
     ]
    }
   ],
   "source": [
    "#print char of feature 1\n",
    "char = np.array(CHARS)\n",
    "\n",
    "#A function for displaying our features in text\n",
    "def print_features(tfeature,label,index):\n",
    "    feature = np.array(tfeature[index],dtype=int).reshape(21,1)\n",
    "    #Convert to string\n",
    "    char_list = char[feature]\n",
    "    left = ''.join(reversed(char_list[10:20].reshape(10))).replace(\" \", \"\")\n",
    "    center = ''.join(char_list[20])\n",
    "    right =  ''.join(char_list[0:10].reshape(10)).replace(\" \", \"\")\n",
    "    word = ''.join([left,' ',center,' ',right])\n",
    "    print(center + ': ' + word + \"\\tpred = \"+str(label[index]))\n",
    "\n",
    "for ind in range(0,30):\n",
    "    print_features(x_train_char,y_train,ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "98d489c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "SimpleFeedforwardNN                      [1, 1]                    --\n",
       "├─Linear: 1-1                            [1, 100]                  2,200\n",
       "├─Linear: 1-2                            [1, 100]                  10,100\n",
       "├─Linear: 1-3                            [1, 100]                  10,100\n",
       "├─Linear: 1-4                            [1, 1]                    101\n",
       "==========================================================================================\n",
       "Total params: 22,501\n",
       "Trainable params: 22,501\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.02\n",
       "==========================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.09\n",
       "Estimated Total Size (MB): 0.09\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "from torchinfo import summary\n",
    "\n",
    "class SimpleFeedforwardNN(torch.nn.Module):\n",
    "  def __init__(self):\n",
    "    super(SimpleFeedforwardNN, self).__init__()\n",
    "\n",
    "    self.mlp1 = torch.nn.Linear(21, 100)\n",
    "    self.mlp2 = torch.nn.Linear(100, 100)\n",
    "    self.mlp3 = torch.nn.Linear(100, 100)\n",
    "    self.cls_head = torch.nn.Linear(100, 1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = F.relu(self.mlp1(x))\n",
    "    x = F.relu(self.mlp2(x))\n",
    "    x = F.relu(self.mlp3(x))\n",
    "    x = self.cls_head(x)\n",
    "    out = torch.sigmoid(x)\n",
    "    return out\n",
    "\n",
    "model = SimpleFeedforwardNN() #Initialize model\n",
    "model.cuda() #specify the location that it is in the GPU\n",
    "summary(model, input_size=(1, 21), device='cuda') #summarize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "036ec492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[112. 140. 114. 148. 130. 142.  94. 142. 128. 128.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.  97.]\n",
      " [140. 114. 148. 130. 142.  94. 142. 128. 128. 141.  97.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1. 112.]\n",
      " [114. 148. 130. 142.  94. 142. 128. 128. 141. 109. 112.  97.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1. 140.]\n",
      " [148. 130. 142.  94. 142. 128. 128. 141. 109. 117. 140. 112.  97.   1.\n",
      "    1.   1.   1.   1.   1.   1. 114.]]\n",
      "(4, 21)\n",
      "torch.Size([4, 3])\n",
      "tensor([[-10.7609,  35.0017, -75.6997],\n",
      "        [-27.3164,  26.4542, -69.2510],\n",
      "        [ -9.0613,  42.3437, -91.1748],\n",
      "        [-21.3748,  35.3703, -57.5476]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mlp_test = torch.nn.Linear(21, 3).cuda() # a MLP that has 21 input nodes and 3 output nodes\n",
    "print(x_train_char[:4])\n",
    "print(x_train_char[:4].shape)\n",
    "test_input = torch.tensor(x_train_char[:4], dtype = torch.float).cuda()\n",
    "print(mlp_test(test_input).shape)\n",
    "print(mlp_test(test_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "261d287c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "  'Characterizes a dataset for PyTorch'\n",
    "  def __init__(self, X, Y, dtype = 'float'):\n",
    "        'Initialization'\n",
    "        self.X = X\n",
    "        self.Y = Y.reshape(-1, 1)\n",
    "        if(dtype == 'float'):\n",
    "          self.X = torch.tensor(self.X, dtype = torch.float).cuda()\n",
    "        elif(dtype == 'long'):\n",
    "          self.X = torch.tensor(self.X, dtype = torch.long).cuda()\n",
    "        self.Y = torch.tensor(self.Y, dtype = torch.float).cuda()\n",
    "\n",
    "  def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.X)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        # Select sample\n",
    "        x = self.X[index]\n",
    "        y = self.Y[index, :]\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "98f0aa74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "#hyperparameter initialization\n",
    "NUM_EPOCHS = 3\n",
    "criterion = torch.nn.BCELoss(reduction = 'none')\n",
    "BATCHS_SIZE = 512\n",
    "optimizer_class = optim.Adam\n",
    "optimizer_params = {'lr': 5e-4}\n",
    "\n",
    "config = {\n",
    "    'architecture': 'simpleff',\n",
    "    'epochs': NUM_EPOCHS,\n",
    "    'batch_size': BATCHS_SIZE,\n",
    "    'optimizer_params': optimizer_params,\n",
    "}\n",
    "\n",
    "train_loader = DataLoader( Dataset(x_train_char, y_train, dtype = 'float'), batch_size = BATCHS_SIZE)\n",
    "val_loader = DataLoader( Dataset(x_val_char, y_val, dtype = 'float'), batch_size = BATCHS_SIZE)\n",
    "test_loader = DataLoader( Dataset(x_test_char, y_test, dtype = 'float'), batch_size = BATCHS_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1c49c86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torchmetrics.functional import accuracy\n",
    "\n",
    "class LightningModel(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model=SimpleFeedforwardNN(),\n",
    "        criterion=criterion,\n",
    "        optimizer_class=optim.Adam,\n",
    "        optimizer_params={'lr': 5e-4}\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.criterion = criterion\n",
    "        self.optimizer_class = optimizer_class\n",
    "        self.optimizer_params = optimizer_params\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        X_train, Y_train = batch\n",
    "        Y_pred = self.model(X_train)\n",
    "        loss = self.criterion(Y_pred, Y_train).mean()\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        X_val, Y_val = batch\n",
    "        Y_pred = self.model(X_val)\n",
    "        loss = self.criterion(Y_pred, Y_val).mean()\n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True)\n",
    "\n",
    "        # Convert probalities to classes.\n",
    "        val_pred = (Y_pred >= 0.5).float()\n",
    "\n",
    "        # Calculate accuracy.\n",
    "        val_acc = accuracy(val_pred, Y_val, task=\"binary\")\n",
    "\n",
    "        self.log('val_accuracy', val_acc, on_step=False, on_epoch=True)\n",
    "        return {'val_loss': loss, 'val_accuracy': val_acc}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return self.optimizer_class(self.parameters(), **self.optimizer_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fcf970e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# Initialize LightningModel.\n",
    "lightning_model = LightningModel(\n",
    "  model,\n",
    "  criterion,\n",
    "  optimizer_class,\n",
    "  optimizer_params,\n",
    ")\n",
    "# Define checkpoint.\n",
    "feedforward_nn_checkpoint = ModelCheckpoint(\n",
    "  monitor=\"val_accuracy\",\n",
    "  mode=\"max\",\n",
    "  save_top_k=1,\n",
    "  dirpath=\"./checkpoints\",\n",
    "  filename='feedforward_nn'\n",
    ")\n",
    "# Initialize Trainer\n",
    "trainer = pl.Trainer(\n",
    "  max_epochs=NUM_EPOCHS,\n",
    "  logger=pl.loggers.WandbLogger(),\n",
    "  callbacks=[feedforward_nn_checkpoint],\n",
    "  accelerator=\"gpu\",\n",
    "  devices=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "462ecd25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "else:\n",
    "    print(\"ไม่มี GPU ที่รองรับ CUDA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "35a86af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to 'default'."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_step</td><td>▇▇▇▆█▅▅▅▇▄▆▅▄▄▅█▂▃▁▄▅▂▆▂▇▆▆▂▅▂▃▂▁▃▄▂▆▂▄▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▂▂▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▅▅▆▆▆▆▆▆▆▇▇▇▇▇████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>train_loss_step</td><td>0.29346</td></tr><tr><td>trainer/global_step</td><td>15499</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">quiet-fog-1</strong> at: <a href='https://wandb.ai/eieizdy007-thammasat-university/simpleff/runs/ia8o7hxq' target=\"_blank\">https://wandb.ai/eieizdy007-thammasat-university/simpleff/runs/ia8o7hxq</a><br> View project at: <a href='https://wandb.ai/eieizdy007-thammasat-university/simpleff' target=\"_blank\">https://wandb.ai/eieizdy007-thammasat-university/simpleff</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250711_223936-ia8o7hxq\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\NLP_learn\\NLP_learn\\wandb\\run-20250711_224557-zg1akkeg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/eieizdy007-thammasat-university/simpleff/runs/zg1akkeg' target=\"_blank\">clear-microwave-2</a></strong> to <a href='https://wandb.ai/eieizdy007-thammasat-university/simpleff' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/eieizdy007-thammasat-university/simpleff' target=\"_blank\">https://wandb.ai/eieizdy007-thammasat-university/simpleff</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/eieizdy007-thammasat-university/simpleff/runs/zg1akkeg' target=\"_blank\">https://wandb.ai/eieizdy007-thammasat-university/simpleff/runs/zg1akkeg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\mini\\envs\\pine\\Lib\\site-packages\\pytorch_lightning\\loggers\\wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type                | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | model     | SimpleFeedforwardNN | 22.5 K | train\n",
      "1 | criterion | BCELoss             | 0      | train\n",
      "----------------------------------------------------------\n",
      "22.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "22.5 K    Total params\n",
      "0.090     Total estimated model params size (MB)\n",
      "6         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\mini\\envs\\pine\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "d:\\mini\\envs\\pine\\Lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   6%|▌         | 1775/32152 [00:31<08:55, 56.74it/s, v_num=kkeg]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  48%|████▊     | 15527/32152 [06:52<07:22, 37.60it/s, v_num=7hxq]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\mini\\envs\\pine\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:48\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     47\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\mini\\envs\\pine\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:599\u001b[39m, in \u001b[36mTrainer._fit_impl\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    593\u001b[39m ckpt_path = \u001b[38;5;28mself\u001b[39m._checkpoint_connector._select_ckpt_path(\n\u001b[32m    594\u001b[39m     \u001b[38;5;28mself\u001b[39m.state.fn,\n\u001b[32m    595\u001b[39m     ckpt_path,\n\u001b[32m    596\u001b[39m     model_provided=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    597\u001b[39m     model_connected=\u001b[38;5;28mself\u001b[39m.lightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    598\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m599\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    601\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.state.stopped\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\mini\\envs\\pine\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1012\u001b[39m, in \u001b[36mTrainer._run\u001b[39m\u001b[34m(self, model, ckpt_path)\u001b[39m\n\u001b[32m   1009\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1010\u001b[39m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[32m   1011\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1012\u001b[39m results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[32m   1015\u001b[39m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[32m   1016\u001b[39m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\mini\\envs\\pine\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:1056\u001b[39m, in \u001b[36mTrainer._run_stage\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1055\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.autograd.set_detect_anomaly(\u001b[38;5;28mself\u001b[39m._detect_anomaly):\n\u001b[32m-> \u001b[39m\u001b[32m1056\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1057\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\mini\\envs\\pine\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:216\u001b[39m, in \u001b[36m_FitLoop.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28mself\u001b[39m.on_advance_start()\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28mself\u001b[39m.on_advance_end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\mini\\envs\\pine\\Lib\\site-packages\\pytorch_lightning\\loops\\fit_loop.py:455\u001b[39m, in \u001b[36m_FitLoop.advance\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    454\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m455\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mepoch_loop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\mini\\envs\\pine\\Lib\\site-packages\\pytorch_lightning\\loops\\training_epoch_loop.py:152\u001b[39m, in \u001b[36m_TrainingEpochLoop.run\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m152\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    153\u001b[39m     \u001b[38;5;28mself\u001b[39m.on_advance_end(data_fetcher)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\mini\\envs\\pine\\Lib\\site-packages\\pytorch_lightning\\loops\\training_epoch_loop.py:306\u001b[39m, in \u001b[36m_TrainingEpochLoop.advance\u001b[39m\u001b[34m(self, data_fetcher)\u001b[39m\n\u001b[32m    305\u001b[39m dataloader_iter = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m306\u001b[39m batch, _, __ = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    307\u001b[39m \u001b[38;5;66;03m# TODO: we should instead use the batch_idx returned by the fetcher, however, that will require saving the\u001b[39;00m\n\u001b[32m    308\u001b[39m \u001b[38;5;66;03m# fetcher state so that the batch_idx is correct after restarting\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\mini\\envs\\pine\\Lib\\site-packages\\pytorch_lightning\\loops\\fetchers.py:134\u001b[39m, in \u001b[36m_PrefetchDataFetcher.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done:\n\u001b[32m    133\u001b[39m     \u001b[38;5;66;03m# this will run only when no pre-fetching was done.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     batch = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__next__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    136\u001b[39m     \u001b[38;5;66;03m# the iterator is empty\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\mini\\envs\\pine\\Lib\\site-packages\\pytorch_lightning\\loops\\fetchers.py:61\u001b[39m, in \u001b[36m_DataFetcher.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m61\u001b[39m     batch = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\mini\\envs\\pine\\Lib\\site-packages\\pytorch_lightning\\utilities\\combined_loader.py:341\u001b[39m, in \u001b[36mCombinedLoader.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m341\u001b[39m out = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m._iterator, _Sequential):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\mini\\envs\\pine\\Lib\\site-packages\\pytorch_lightning\\utilities\\combined_loader.py:78\u001b[39m, in \u001b[36m_MaxSizeCycle.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     out[i] = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterators\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\mini\\envs\\pine\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:731\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> Any:\n\u001b[32m--> \u001b[39m\u001b[32m731\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprofiler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecord_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_profile_name\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    732\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    733\u001b[39m             \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\mini\\envs\\pine\\Lib\\site-packages\\torch\\autograd\\profiler.py:776\u001b[39m, in \u001b[36mrecord_function.__exit__\u001b[39m\u001b[34m(self, exc_type, exc_value, traceback)\u001b[39m\n\u001b[32m    774\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m776\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type: Any, exc_value: Any, traceback: Any):\n\u001b[32m    777\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.run_callbacks_on_exit:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[50]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      2\u001b[39m wandb.init(\n\u001b[32m      3\u001b[39m     project=\u001b[33m'\u001b[39m\u001b[33msimpleff\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      4\u001b[39m     config=config,\n\u001b[32m      5\u001b[39m )\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Fit model.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlightning_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBest model is saved at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeedforward_nn_checkpoint.best_model_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\mini\\envs\\pine\\Lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py:561\u001b[39m, in \u001b[36mTrainer.fit\u001b[39m\u001b[34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[39m\n\u001b[32m    559\u001b[39m \u001b[38;5;28mself\u001b[39m.training = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    560\u001b[39m \u001b[38;5;28mself\u001b[39m.should_stop = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m561\u001b[39m \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    562\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\mini\\envs\\pine\\Lib\\site-packages\\pytorch_lightning\\trainer\\call.py:65\u001b[39m, in \u001b[36m_call_and_handle_interrupt\u001b[39m\u001b[34m(trainer, trainer_fn, *args, **kwargs)\u001b[39m\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[32m     64\u001b[39m         launcher.kill(_get_sigkill_signal())\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m     \u001b[43mexit\u001b[49m(\u001b[32m1\u001b[39m)\n\u001b[32m     67\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[32m     68\u001b[39m     _interrupt(trainer, exception)\n",
      "\u001b[31mNameError\u001b[39m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "# Initialize wandb to log the losses from each step.\n",
    "wandb.init(\n",
    "    project='simpleff',\n",
    "    config=config,\n",
    ")\n",
    "# Fit model.\n",
    "trainer.fit(lightning_model, train_loader, val_loader)\n",
    "\n",
    "print(f\"Best model is saved at {feedforward_nn_checkpoint.best_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b4a67b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score,precision_score,recall_score\n",
    "\n",
    "################################################################################\n",
    "# A function to evaluate your model. This function must take test dataloader   #\n",
    "# and the input model to return f-score, precision, and recall of the model.   #\n",
    "################################################################################\n",
    "def evaluate(test_loader, model):\n",
    "  \"\"\"\n",
    "  Evaluate model on the splitted 10 percent testing set.\n",
    "  \"\"\"\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    test_loss = []\n",
    "    test_pred = []\n",
    "    test_true = []\n",
    "    for X_test, Y_test in tqdm(test_loader):\n",
    "      Y_pred = model(X_test)\n",
    "      loss = criterion(Y_pred, Y_test)\n",
    "      test_loss.append(loss)\n",
    "      test_pred.append(Y_pred)\n",
    "      test_true.append(Y_test)\n",
    "\n",
    "    avg_test_loss = torch.cat(test_loss, axis = 0).mean().item()\n",
    "    test_pred = torch.cat(test_pred, axis = 0).cpu().detach().numpy()\n",
    "    test_true = torch.cat(test_true, axis = 0).cpu().detach().numpy()\n",
    "\n",
    "    prob_to_class = lambda p: 1 if p[0]>=0.5 else 0\n",
    "    test_pred = np.apply_along_axis(prob_to_class,1,test_pred)\n",
    "\n",
    "    acc = accuracy_score(test_true, test_pred)\n",
    "    f1score = f1_score(test_true, test_pred)\n",
    "    precision = precision_score(test_true, test_pred)\n",
    "    recall = recall_score(test_true, test_pred)\n",
    "\n",
    "  return {\n",
    "    \"accuracy\": acc,\n",
    "    \"f1_score\": f1score,\n",
    "    \"precision\": precision,\n",
    "    \"recall\": recall\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e83a44b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'd:/NLP_learn/NLP_learn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPermissionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m best_model_path = feedforward_nn_checkpoint.best_model_path\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# best_model_path = ... # Insert if you have already trained this model.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m best_model = \u001b[43mLightningModel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_model_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mSimpleFeedforwardNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m result = evaluate(test_loader, best_model)\n\u001b[32m      7\u001b[39m wandb.finish()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\mini\\envs\\pine\\Lib\\site-packages\\pytorch_lightning\\utilities\\model_helpers.py:125\u001b[39m, in \u001b[36m_restricted_classmethod_impl.__get__.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    120\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m instance \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scripting:\n\u001b[32m    121\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    122\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe classmethod `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.method.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` cannot be called on an instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    123\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m Please call it on the class type and make sure the return value is used.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    124\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\mini\\envs\\pine\\Lib\\site-packages\\pytorch_lightning\\core\\module.py:1611\u001b[39m, in \u001b[36mLightningModule.load_from_checkpoint\u001b[39m\u001b[34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[39m\n\u001b[32m   1522\u001b[39m \u001b[38;5;129m@_restricted_classmethod\u001b[39m\n\u001b[32m   1523\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_from_checkpoint\u001b[39m(\n\u001b[32m   1524\u001b[39m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1529\u001b[39m     **kwargs: Any,\n\u001b[32m   1530\u001b[39m ) -> Self:\n\u001b[32m   1531\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint it stores the arguments\u001b[39;00m\n\u001b[32m   1532\u001b[39m \u001b[33;03m    passed to ``__init__``  in the checkpoint under ``\"hyper_parameters\"``.\u001b[39;00m\n\u001b[32m   1533\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   1609\u001b[39m \n\u001b[32m   1610\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1611\u001b[39m     loaded = \u001b[43m_load_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1612\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1613\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1614\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1615\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhparams_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1616\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1617\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1618\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1619\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(Self, loaded)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\mini\\envs\\pine\\Lib\\site-packages\\pytorch_lightning\\core\\saving.py:63\u001b[39m, in \u001b[36m_load_from_checkpoint\u001b[39m\u001b[34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[39m\n\u001b[32m     61\u001b[39m map_location = map_location \u001b[38;5;129;01mor\u001b[39;00m _default_map_location\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m pl_legacy_patch():\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m     checkpoint = \u001b[43mpl_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# convert legacy checkpoints to the new format\u001b[39;00m\n\u001b[32m     66\u001b[39m checkpoint = _pl_migrate_checkpoint(\n\u001b[32m     67\u001b[39m     checkpoint, checkpoint_path=(checkpoint_path \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(checkpoint_path, (\u001b[38;5;28mstr\u001b[39m, Path)) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     68\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\mini\\envs\\pine\\Lib\\site-packages\\lightning_fabric\\utilities\\cloud_io.py:60\u001b[39m, in \u001b[36m_load\u001b[39m\u001b[34m(path_or_url, map_location, weights_only)\u001b[39m\n\u001b[32m     54\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.hub.load_state_dict_from_url(\n\u001b[32m     55\u001b[39m         \u001b[38;5;28mstr\u001b[39m(path_or_url),\n\u001b[32m     56\u001b[39m         map_location=map_location,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m     57\u001b[39m         weights_only=weights_only,\n\u001b[32m     58\u001b[39m     )\n\u001b[32m     59\u001b[39m fs = get_filesystem(path_or_url)\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mfs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     61\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.load(\n\u001b[32m     62\u001b[39m         f,\n\u001b[32m     63\u001b[39m         map_location=map_location,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m     64\u001b[39m         weights_only=weights_only,\n\u001b[32m     65\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\mini\\envs\\pine\\Lib\\site-packages\\fsspec\\spec.py:1301\u001b[39m, in \u001b[36mAbstractFileSystem.open\u001b[39m\u001b[34m(self, path, mode, block_size, cache_options, compression, **kwargs)\u001b[39m\n\u001b[32m   1299\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1300\u001b[39m     ac = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mautocommit\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._intrans)\n\u001b[32m-> \u001b[39m\u001b[32m1301\u001b[39m     f = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1302\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1303\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1304\u001b[39m \u001b[43m        \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1305\u001b[39m \u001b[43m        \u001b[49m\u001b[43mautocommit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mac\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1306\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1307\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1308\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1309\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1310\u001b[39m         \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfsspec\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcompression\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m compr\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\mini\\envs\\pine\\Lib\\site-packages\\fsspec\\implementations\\local.py:195\u001b[39m, in \u001b[36mLocalFileSystem._open\u001b[39m\u001b[34m(self, path, mode, block_size, **kwargs)\u001b[39m\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auto_mkdir \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m    194\u001b[39m     \u001b[38;5;28mself\u001b[39m.makedirs(\u001b[38;5;28mself\u001b[39m._parent(path), exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m195\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mLocalFileOpener\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\mini\\envs\\pine\\Lib\\site-packages\\fsspec\\implementations\\local.py:359\u001b[39m, in \u001b[36mLocalFileOpener.__init__\u001b[39m\u001b[34m(self, path, mode, autocommit, fs, compression, **kwargs)\u001b[39m\n\u001b[32m    357\u001b[39m \u001b[38;5;28mself\u001b[39m.compression = get_compression(path, compression)\n\u001b[32m    358\u001b[39m \u001b[38;5;28mself\u001b[39m.blocksize = io.DEFAULT_BUFFER_SIZE\n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\mini\\envs\\pine\\Lib\\site-packages\\fsspec\\implementations\\local.py:364\u001b[39m, in \u001b[36mLocalFileOpener._open\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    362\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.f.closed:\n\u001b[32m    363\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.autocommit \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.mode:\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m         \u001b[38;5;28mself\u001b[39m.f = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    365\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.compression:\n\u001b[32m    366\u001b[39m             compress = compr[\u001b[38;5;28mself\u001b[39m.compression]\n",
      "\u001b[31mPermissionError\u001b[39m: [Errno 13] Permission denied: 'd:/NLP_learn/NLP_learn'"
     ]
    }
   ],
   "source": [
    "# Load best model and evaluate it.\n",
    "best_model_path = feedforward_nn_checkpoint.best_model_path\n",
    "# best_model_path = ... # Insert if you have already trained this model.\n",
    "best_model = LightningModel.load_from_checkpoint(best_model_path, model=SimpleFeedforwardNN())\n",
    "result = evaluate(test_loader, best_model)\n",
    "\n",
    "wandb.finish()\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
